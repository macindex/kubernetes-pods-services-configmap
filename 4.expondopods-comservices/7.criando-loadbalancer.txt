Entender o que é um LoadBalancer depois que nós já entendemos do que se trata um NodePort e um ClusterIP é bem fácil - principalmente porque o LoadBalancernada mais é do que um ClusterIP que permite a comunicação entre uma mna do mundo externo e os nosso pods. Só que ele automaticamente se integra ao LoadBalancerdo nosso cloud provider.
Ícone proeminente de "SVC" com legenda "LoadBalancer". Ao lado, a área tracejada de "Cluster" contém os logotipos de "AWS", Google Cloud e Azure, ligados a dois ícones de "SVC". No primeiro, há conexão com três pods, e o segundo com apenas um.
Então quando nós criamos um LoadBalancer ele vai utilizar automaticamente, sem nenhum esforço manual, o cloud provider da AWS ou do Google Cloud Platform ou da Azure, e assim por diante.
Mesma imagem anterior, porém com o texto "Abre comunicação para o mundo externo usando o Load Balancer do provedor! ao lado do ícone poreminente de "SVC" com legenda "LoadBalancer"
Então, vamos ! Eu vou pegar o nosso pod-1 que nós viemos trabalhando e vou criar esse mesmo pod no nosso cluster do Google Cloud Platform.
Vou colocar o arquivo, vou criar ele com as mesmas definições que eu acabei de copiar ali, vou colar, vou digitar um apply, kubectl apply –f e passar o nosso pod-1.yaml. Ele foi criado sem nenhum problema, nós digitamos um kubectl get pods, ele foi criado e agora nós precisamos criar o nosso LoadBalancer.
Então eu vou criar no Visual Studio Code para nós conseguirmos visualizar melhor. Nós vamos fazer o seguinte: vamos criar o nosso svc-pod-1-loadbalancer.yaml e dentro dele nós vamos definir mais uma vez a versão da nossa API como V1. O que nós queremos criar continua sendo um service e em metadata vamos chamar ele também pelo name: svc-pod-1-loadbalancer.
nas especificações nós vamos definir o tipo que vai ser o nosso type: LoadBalancer, agora sem nenhum problema. em ports: nós vamos definir a nossa porta de entrada, onde nós podemos ir definindo. Nós queremos que dentro do cluster.
Como ele é um NodePort, ele também é um ClusterIP, ele ouça na porta 80 e despacha também para a porta 80, dentro do cluster. E que também o nosso nodePort : 30000, por exemplo. Nós podemos fazer essa definição.
Por fim, falta apenas nós selecionarmos qual é o nosso pod. Nesse caso vamos definir a label com a chave API e o valor primeiro pod.
Tudo perfeito! Basta agora nós copiarmos essas mesma definição, vir no nosso Google Cloud Platform e criar esse arquivo que vai ser o nosso “lb.yaml”. Nós colamos sem nenhum mistério: kubectl apply -f lb.yaml e ele vai criar para nós sem nenhum problema.
Se nós viermos agora dentro do nosso cluster na atividade na parte visual dele, nós conseguimos vir em “Serviços e entradas” e olhe só que legal: está - o nosso serviço que nós acabamos de criar! E mostra que tem 1 de 1 pod sendo gerenciado por ele no nosso “cluster-1”.
Ele está terminando de criar os endpoints para acesso. Se nós continuarmos atualizando, vai ser bem rapidinho, nós vamos conseguir acessar esse nosso pod a partir do próprio navegador.
Então se vocês estivessem assistindo agora em tempo real, vocês também conseguiriam ao mesmo tempo que eu fazer o acesso a esse pod, porque nesse exato momento ele está sendo publicado e sendo possivelmente acessado com o LoadBalancer do Google Cloud Platform - já tudo integrado sem nenhum problema, sem nenhuma configuração adicional na gestão de balanceamento de carga que acabou de ficar pronto.
Basta nós clicarmos no link que foi gerado o do IP. Ele está alertando sobre o redirecionamento e está o nosso nginx, que é o nosso pod-1 sem nenhum problema na web. Olhe que legal e fácil, bem simples!
Então agora que nós já nos familiarizamos com os três tipos de serviço, ClusterIP, NodePort e LoadBalancer, nós vamos colocar eles na prática em uma aula em que nós vamos trabalhar com eles em cima do nosso projeto, do portal de notícias e nós vamos sedimentar o conteúdo que nós aprendemos agora nessas últimas aulas.
Então é isso por esse vídeo. Eu vejo vocês no próximo e até mais!

